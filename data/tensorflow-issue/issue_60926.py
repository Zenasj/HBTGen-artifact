# tf.random.uniform((num_examples, 1024), dtype=tf.complex64) ‚Üê input shape inferred from training data creation

import tensorflow as tf
import numpy as np
from scipy.linalg import dft

class FFTLayer(tf.keras.layers.Layer):
    def call(self, x):
        # Perform FFT using TensorFlow's tf.signal.fft
        return tf.signal.fft(x)

class MatrixDFTLayer(tf.keras.layers.Layer):
    def __init__(self):
        super().__init__()
        # Create DFT matrix of size 1024x1024, cast to complex64
        self.dft = tf.constant(dft(1024), dtype=tf.complex64)

    def call(self, x):
        # Compute DFT by matrix multiplication (dft @ x^T)^T to match FFT output shape
        # x shape: [batch_size, 1024]
        fx = self.dft @ tf.transpose(x)   # Shape: (1024, batch_size)
        return tf.transpose(fx)            # Shape: (batch_size, 1024)

class MyModel(tf.keras.Model):
    def __init__(self):
        super().__init__()
        # Instantiate both layers
        self.fft_layer = FFTLayer()
        self.dft_layer = MatrixDFTLayer()

    def call(self, inputs):
        """
        Forward pass computes FFT and DFT outputs for input and compares equality
        within a tolerance.

        inputs: tf.Tensor of shape [batch_size, 1024], dtype complex64
        returns: boolean tensor of shape [batch_size, 1024],
                 True where FFT and DFT outputs match closely, False otherwise
        """
        fft_output = self.fft_layer(inputs)
        dft_output = self.dft_layer(inputs)
        # Because of floating point differences, compare with a small tolerance
        close = tf.math.abs(fft_output - dft_output) < 1e-5
        return close

def my_model_function():
    # Return instance of MyModel
    return MyModel()

def GetInput():
    """
    Generates input matching what MyModel expects.

    From the original issue:
    - Input shape: [num_examples, 1024]
    - dtype: tf.complex64
    The input is generated by taking IFFT of a complex vector train_y of all (1/sqrt(2) + (1/sqrt(2))j),
    then tiled across batch dimension.

    For simplicity, we replicate that logic to produce one batch.

    Returns:
        tf.Tensor of shape [batch_size, 1024], dtype tf.complex64
    """
    fft_size = 1024
    batch_size = 9  # match the example batch size

    # Create complex vector train_y with all entries (1/sqrt(2) + 1/sqrt(2)j)
    val = 1 / np.sqrt(2)
    train_y = (val + 1j * val) * np.ones(fft_size, dtype=np.complex64)

    # Take inverse FFT to get input space
    train_x = tf.signal.ifft(train_y)
    train_x = tf.cast(train_x, tf.complex64)  # ensure dtype

    # Tile train_x batch_size times along batch dimension
    inputs = tf.tile(tf.expand_dims(train_x, 0), [batch_size, 1])

    return inputs


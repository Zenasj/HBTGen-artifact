import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import os
import torch.nn.functional as F
gpu_device = torch.device("cuda")
cpu_device = torch.device("cpu")
class PreprocessAndCalculateModel(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x):
        # = x.view(x.size(0), -1
        output = torch.xlogy(x, x)
        return output


real_inputs = torch.Tensor([[[[ 3.3164e-01,  6.9911e-01,  6.3390e-01,  1.9640e-01,  7.9174e-01,
            7.7003e-01,  3.1660e-01,  3.2423e-01],
          [ 9.1965e-01,  7.9635e-01,  7.7244e-01,  6.6584e-01,  4.9332e-01,
            3.3407e-01,  9.9149e-01,  7.7064e-01],
          [ 1.0035e+00,  8.2132e-01,  4.7497e-01,  8.8504e-01,  4.8966e-01,
            8.7896e-01,  4.7476e-01,  4.0221e-01],
          [ 8.2481e-01,  7.0815e-01,  7.6464e-01,  2.7595e-01,  3.4665e-01,
            2.1680e-01,  8.8801e-01,  6.1765e-02],
          [ 8.5625e-01,  9.0374e-01,  7.1288e-01,  6.5885e-02,  9.2502e-01,
            6.7810e-04,  1.0306e+00,  7.5104e-01],
          [ 8.3710e-01,  5.4719e-01,  7.2544e-01,  1.2516e-01,  5.1978e-02,
            7.3132e-01,  2.7550e-02,  1.0215e+00],
          [ 1.0598e+00,  7.2862e-01,  8.7616e-01,  7.9756e-01,  4.5157e-01,
            1.0177e+00,  4.0120e-01,  3.6222e-01],
          [ 5.4733e-01,  6.7129e-01,  7.2430e-02,  4.3001e-02,  7.5020e-02,
            4.5803e-01,  3.6475e-01,  2.3184e-01]],

         [[ 8.0688e-01,  8.1802e-01,  7.0586e-01,  8.7644e-01,  3.7983e-01,
            4.3956e-01,  9.6551e-01,  2.0901e-01],
          [ 1.6635e-01,  6.0298e-01,  6.9616e-01,  1.1466e-01,  3.3594e-01,
            1.0236e+00,  1.4471e-02,  2.8666e-01],
          [ 2.5714e-01,  1.9311e-01,  2.0202e-01,  4.6973e-01,  8.9814e-01,
            7.3549e-01,  6.3174e-01,  5.0010e-01],
          [ 8.6298e-01,  8.1399e-01,  3.1544e-01,  4.2865e-01,  6.8145e-01,
            7.3575e-02,  1.9854e-01,  3.5585e-01],
          [ 4.0481e-01,  3.0573e-02,  6.3521e-01,  2.9207e-01,  1.5961e-01,
            6.3168e-01,  9.6864e-01,  5.8929e-01],
          [ 4.7391e-01,  2.9919e-01,  9.8137e-01,  5.7918e-01,  8.7368e-01,
            2.5659e-01,  1.9292e-02,  8.0696e-01],
          [ 9.1690e-01,  4.5762e-01,  8.9138e-02,  4.9913e-01,  8.6114e-01,
            6.5269e-01,  8.6706e-01,  1.8487e-01],
          [ 4.5451e-01,  4.5671e-01,  1.9308e-01,  6.2311e-01,  1.7749e-02,
            9.3052e-01,  2.2440e-01,  6.2985e-01]],

         [[ 9.8373e-02,  3.1071e-01,  9.4979e-02,  1.8212e-01,  2.9907e-01,
            9.4827e-02,  1.8307e-01,  9.8376e-01],
          [ 7.9090e-01,  9.1842e-01,  7.0425e-01,  5.2234e-02,  5.4220e-01,
            3.7509e-01,  9.7987e-02,  7.4120e-01],
          [ 4.7188e-01,  7.4300e-01,  1.0145e+00,  7.5025e-01,  2.0469e-01,
            9.2829e-01,  9.1202e-01,  8.5070e-01],
          [ 3.6781e-01,  2.2302e-01,  7.4533e-01,  3.7615e-02,  4.8050e-01,
            6.6318e-01,  7.7393e-01,  5.9202e-01],
          [ 9.5152e-01,  4.8788e-01,  7.5432e-01,  2.1582e-01,  6.9101e-01,
            8.2021e-01,  7.2083e-01,  1.3023e-01],
          [ 5.4081e-01,  9.6481e-01,  4.4658e-01,  3.8257e-01,  3.3657e-01,
            3.1550e-01,  5.7981e-01,  1.9741e-01],
          [ 7.9394e-01,  4.9317e-02,  3.5677e-01,  5.0392e-01,  2.1741e-01,
            3.9941e-02,  6.1702e-01, -2.1186e-02],
          [ 3.2865e-01,  3.9422e-01,  8.7310e-01,  8.0029e-01,  8.7788e-02,
            1.0121e+00,  6.5862e-02,  7.4595e-01]]],


        [[[ 5.6442e-01,  7.7583e-01,  2.7320e-01,  8.7671e-01,  6.8483e-01,
            5.3765e-01,  6.6209e-01,  5.9765e-01],
          [ 6.7418e-01,  8.2308e-01,  9.4361e-01,  3.0986e-01,  5.6889e-01,
            8.5727e-01,  7.2988e-03,  1.7841e-01],
          [ 5.3998e-01,  4.9308e-01,  4.4273e-01,  1.0128e+00,  2.5949e-01,
            5.8150e-01,  8.9576e-01,  8.1126e-01],
          [ 8.0811e-01,  6.1441e-01,  3.2785e-01,  4.3908e-01,  1.7451e-01,
            1.0115e+00,  7.1194e-01,  7.3850e-01],
          [ 8.2712e-01,  7.9248e-01,  4.4033e-01,  3.0063e-01,  3.2542e-01,
            7.7894e-01,  1.0749e-01,  8.7530e-01],
          [ 2.5312e-01,  9.9069e-01,  5.7443e-01,  1.0164e+00,  6.9583e-01,
            7.9087e-01,  8.4193e-01,  1.7599e-01],
          [ 1.0145e+00,  2.2992e-01,  9.4180e-01,  4.3618e-01,  4.2863e-01,
            5.7330e-01,  1.8107e-01,  2.2379e-01],
          [ 1.0184e+00,  7.0164e-01,  8.9178e-01,  1.4606e-01,  2.5110e-02,
            6.1831e-01,  8.7412e-01,  8.0826e-02]],

         [[ 7.4417e-01,  3.4383e-01,  6.6420e-01,  6.4870e-02,  7.7854e-01,
            2.0740e-01,  7.5716e-01,  6.1378e-01],
          [ 8.0816e-01,  3.1974e-02, -2.2928e-02,  1.1567e-01,  1.6197e-01,
            4.8277e-01,  1.0071e+00,  7.6094e-01],
          [ 9.9785e-01,  7.5686e-01,  8.4970e-01,  3.4038e-01,  6.7192e-01,
            2.1788e-01,  1.0217e+00,  1.4312e-01],
          [ 6.0448e-01,  1.1041e-01,  7.8118e-01,  8.5598e-01,  1.9389e-01,
            4.2258e-01,  9.4675e-01,  8.8776e-01],
          [ 9.7778e-01,  4.9596e-01, -2.2949e-02,  3.9247e-01,  8.1049e-01,
            8.2374e-01,  1.5349e-01,  6.9717e-01],
          [ 2.2083e-01,  2.3136e-01,  7.3064e-01,  3.8616e-01,  1.8953e-01,
            1.3853e-01,  1.0363e+00,  1.7717e-01],
          [ 2.8880e-01,  7.5463e-01,  4.9238e-02,  9.8870e-01,  3.0816e-01,
            8.6076e-01,  5.0350e-01,  4.8637e-01],
          [ 4.7812e-01,  2.5256e-01,  9.9369e-01,  7.9527e-01,  4.5035e-01,
            6.1128e-01,  1.0398e-01,  1.0110e+00]],

         [[ 3.0975e-01,  6.8907e-01,  1.7261e-01,  3.9071e-01,  9.2666e-01,
            9.8439e-01,  2.6158e-01,  3.5383e-01],
          [ 9.2105e-01,  4.8278e-01,  9.9360e-01,  1.6408e-01,  5.7905e-01,
            9.7137e-01,  1.3293e-01,  6.2185e-01],
          [ 1.3117e-01,  3.7269e-01,  2.2030e-01,  2.7509e-01,  4.0283e-01,
            4.3685e-01,  9.4379e-01,  5.6995e-01],
          [ 7.9210e-01,  7.6991e-01,  5.7262e-01,  2.5089e-01,  9.3838e-01,
            2.3991e-01,  6.2885e-01,  7.1666e-01],
          [ 8.1981e-01,  2.3727e-01,  7.8893e-01,  5.0486e-01,  5.4864e-01,
            6.0399e-01,  2.9574e-02,  7.1356e-01],
          [ 3.5183e-01,  2.3232e-01,  3.3010e-01,  1.0399e+00,  6.4669e-01,
            6.4994e-01,  8.7485e-01,  6.3156e-01],
          [ 8.5036e-01,  9.9909e-01,  9.9250e-01,  5.8077e-01,  3.3134e-02,
            8.4959e-01,  6.6240e-02,  7.1624e-01],
          [ 1.9952e-01,  8.8744e-02,  8.3780e-01,  8.0945e-01,  3.5926e-01,
            9.5026e-01,  7.0639e-01,  1.0095e+00]]]])
model = PreprocessAndCalculateModel()
x = real_inputs
output_gpu = model.to(gpu_device)(x.cuda())
output_cpu = model.to(cpu_device)(x.cpu())
print(torch.isnan(output_gpu).any())
print(torch.isnan(output_gpu).any())
import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import os
import torch.nn.functional as F
gpu_device = torch.device("cuda")
cpu_device = torch.device("cpu")
class PreprocessAndCalculateModel(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x):
        device = x.device
        output = x.data_ptr()
        return output

real_inputs = torch.Tensor([[[ 4.0088e-01,  6.7996e-01,  9.9518e-01,  2.7397e-01,  1.5877e-02,
           6.3758e-02,  9.8371e-01,  6.5482e-01,  7.4479e-02,  2.2439e-01,
           4.9000e-02,  9.9847e-01,  3.1119e-02,  9.9242e-01,  8.4426e-01,
           6.4544e-01,  2.9861e-01,  6.6590e-01,  8.7287e-01, -1.3281e-02,
           5.9089e-01,  2.0718e-02,  2.7051e-01,  6.9450e-01,  7.3100e-01,
           2.5556e-02,  9.5114e-01,  9.9992e-01,  6.5539e-02,  1.0128e-02,
           4.4205e-02, -7.3132e-03,  5.1426e-02,  2.4806e-02,  3.0370e-01,
           8.7889e-01,  4.6152e-02,  1.3907e-01,  4.7473e-02,  8.3460e-01,
           9.8828e-01,  9.8225e-01,  6.5564e-01,  8.6221e-01,  4.6066e-01,
           9.9666e-01,  1.1731e-02,  6.9353e-01,  6.2739e-01,  9.5019e-01,
           7.9262e-01,  3.5633e-01,  9.9802e-01,  1.4958e-01,  8.9566e-01,
           6.4146e-02,  6.5143e-02,  7.0098e-01,  6.1565e-01,  9.9355e-01,
           9.8682e-01,  4.3897e-02,  4.2700e-01,  9.7346e-01],
         [-2.8668e-03,  2.9202e-01,  9.9911e-01,  1.0259e-01,  3.6130e-01,
           6.9244e-01,  5.8391e-01,  9.9699e-01,  9.8852e-01,  1.3143e-02,
           4.8486e-01,  4.3575e-01,  6.9093e-02,  4.8582e-01,  2.7833e-01,
           9.9983e-01,  9.1201e-01,  2.1180e-01,  7.8027e-03,  4.0605e-02,
           6.1003e-03,  9.3104e-02,  6.3689e-02,  8.6293e-03,  9.7939e-01,
           6.7646e-01,  1.9094e-01,  3.3140e-01,  1.1885e-02,  9.0059e-01,
           7.3878e-03,  1.1160e-01,  3.6539e-01,  5.7985e-01,  7.2714e-01,
           6.2236e-01,  3.3381e-01,  1.4488e-01,  5.6196e-02,  9.9953e-01,
           1.2208e-01,  9.9546e-01,  9.9848e-01,  5.2302e-01,  8.5867e-01,
           8.0977e-01,  6.4911e-01,  5.1940e-01,  3.0724e-01,  1.8298e-02,
           5.6264e-01,  6.0983e-01,  9.7865e-02,  9.8235e-01,  1.5424e-01,
           8.1621e-01,  5.5503e-02,  3.8928e-01,  8.9991e-01,  6.4651e-02,
           6.9823e-01,  9.4306e-01,  3.1622e-02,  7.0519e-01],
         [ 4.3202e-01,  5.9009e-01,  5.5231e-01, -3.8394e-03,  5.3293e-01,
           5.1469e-01,  9.8231e-01,  7.6894e-01,  9.9807e-01,  9.9956e-01,
           8.7547e-01,  8.1045e-01,  9.4093e-01,  1.2744e-01,  5.4302e-02,
           9.5654e-01,  7.5221e-01,  9.2257e-01,  9.8443e-01,  9.6082e-01,
           2.3129e-01,  4.1027e-01,  5.9720e-02,  2.4109e-01, -7.5703e-03,
           8.3967e-02,  5.3393e-01,  2.7103e-02,  1.2856e-02,  3.6917e-01,
           2.9559e-03,  1.6889e-01,  4.7759e-01,  4.3511e-02,  1.4141e-01,
           9.1495e-01,  8.1836e-02,  1.5664e-01,  9.9986e-01,  8.8023e-03,
          -3.3846e-04,  1.2515e-01,  1.5681e-01,  9.9728e-01,  1.1284e-01,
           2.5486e-01,  4.7086e-02,  1.4842e-01,  2.6621e-01, -4.2680e-03,
           9.9573e-01,  6.4797e-01,  2.1977e-02,  3.0604e-01,  2.1213e-04,
           2.8134e-01,  2.5137e-02,  6.7261e-01,  9.3939e-01,  8.4262e-01,
           8.9649e-01,  1.0583e-02,  6.5395e-01,  6.0892e-02]],

        [[ 8.7996e-01,  8.3929e-01,  1.7803e-02, -5.5087e-03,  3.1481e-01,
           6.9976e-01,  1.3912e-01,  3.3547e-01,  5.1633e-01,  1.0312e-01,
           5.8992e-01,  3.5032e-01,  8.5669e-03,  8.1028e-01,  1.5950e-01,
           1.6323e-02,  8.8715e-01,  9.9960e-01,  1.0000e+00,  3.0604e-01,
           9.8396e-01,  6.2602e-01,  2.9008e-02,  4.6577e-01,  9.6102e-01,
           3.7769e-01,  8.2600e-01,  9.3056e-01,  1.5366e-01,  1.2380e-01,
           1.6186e-01,  6.8177e-02,  9.3928e-01,  9.9987e-01,  1.5455e-01,
           2.0075e-01,  1.5837e-01,  4.4558e-01,  8.2306e-02,  3.7032e-01,
           8.7736e-02,  9.7370e-02,  2.5528e-02,  9.1490e-02,  8.7788e-01,
           1.6773e-01,  6.1809e-02,  9.9327e-01,  3.2754e-01,  6.0298e-01,
           4.8896e-01,  7.6949e-02,  9.9299e-01,  8.5610e-01,  1.9104e-03,
           9.4769e-01,  6.9012e-01,  7.4250e-01,  5.6456e-01,  9.7634e-01,
           1.5751e-01,  8.4808e-02,  1.6929e-02,  5.1751e-01],
         [ 1.4185e-01,  8.5981e-01,  2.0381e-01,  4.3451e-01,  1.9104e-01,
           4.7095e-01,  1.1595e-01,  7.3896e-02,  7.7849e-01,  4.7005e-01,
           6.1015e-02,  4.3425e-02,  9.9766e-01,  7.9742e-01,  2.4684e-01,
           3.9073e-02,  8.6468e-02,  4.4355e-02,  3.5537e-02,  4.1323e-01,
           7.5644e-01,  5.2982e-02,  9.9950e-01,  9.9999e-01,  3.9944e-01,
           8.7862e-01,  2.6257e-02,  3.6749e-01,  1.1846e-01,  9.9004e-01,
           9.8312e-01,  4.1760e-01,  6.4248e-01,  6.0216e-01,  3.7382e-01,
           9.5234e-02,  2.1557e-01,  5.2191e-01,  5.8418e-02,  5.3454e-01,
           5.0916e-01,  9.9555e-01,  7.7846e-01,  9.0358e-01,  8.0351e-01,
           5.9525e-02, -5.0039e-03,  6.2632e-01,  9.5858e-01,  6.9640e-01,
           9.2083e-03,  9.3631e-01, -1.8940e-02,  9.9994e-01,  8.6619e-01,
           9.0904e-01, -1.0182e-02,  9.9425e-01,  1.8416e-01,  2.1943e-01,
           3.5414e-01,  3.5645e-02,  1.8658e-01,  2.8371e-02],
         [ 1.9305e-01,  2.6935e-01,  3.9865e-01,  4.8582e-02,  8.3632e-01,
           9.2241e-01,  7.9974e-01,  1.0447e-02,  3.5566e-01,  8.2802e-01,
           4.9066e-02,  7.4757e-01, -6.4720e-03,  5.5995e-01,  1.5454e-01,
           5.8627e-03,  7.2580e-02,  9.6184e-01,  9.2341e-02,  1.4600e-01,
          -7.6448e-03,  7.3432e-01,  5.9362e-01,  4.3654e-03,  9.0709e-01,
           9.9978e-01,  4.8510e-01,  6.9649e-02,  2.9987e-01,  4.7003e-01,
           2.6116e-01,  4.3953e-01,  9.6088e-01,  1.2133e-02,  8.2571e-01,
           7.4916e-01, -1.4240e-03,  5.1918e-01,  7.6099e-01,  2.0639e-02,
           9.8066e-02,  3.7340e-01,  1.1880e-01,  8.9329e-01,  2.6636e-01,
           7.1159e-01,  1.1257e-01,  9.6705e-01,  2.1943e-01,  8.5280e-01,
           1.0928e-02,  8.3419e-01,  2.5332e-01,  1.7777e-03,  2.3317e-01,
           2.4671e-01,  3.9205e-01,  9.9911e-01,  2.5307e-01,  1.5809e-01,
           9.0643e-01,  5.9346e-01,  3.7340e-01, -1.5492e-02]]])
#real_inputs = torch.rand(2, 3, 8, 8,8)
model = PreprocessAndCalculateModel()
x = real_inputs
output_gpu = model.to(gpu_device)(x.cuda())
output_cpu = model.to(cpu_device)(x.cpu())
print(output_gpu)
print(output_cpu)
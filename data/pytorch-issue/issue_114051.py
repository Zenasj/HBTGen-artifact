import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import os
import torch.nn.functional as F
gpu_device = torch.device("cuda")
cpu_device = torch.device("cpu")
class PreprocessAndCalculateModel(nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, x):
        device = x.device
        output =  torch.pinverse(x)
        return output

real_inputs = torch.Tensor([[[[0.6509, 0.6633, 0.6640, 0.6603, 0.6568, 0.6593, 0.6633, 0.6494],
          [0.6543, 0.6622, 0.6583, 0.6539, 0.6606, 0.6622, 0.6532, 0.6614],
          [0.6593, 0.6564, 0.6535, 0.6588, 0.6443, 0.6621, 0.6566, 0.6398],
          [0.6495, 0.6630, 0.6636, 0.6636, 0.6626, 0.6634, 0.6549, 0.6562],
          [0.6586, 0.6594, 0.6618, 0.6593, 0.6405, 0.6359, 0.6531, 0.6627],
          [0.6451, 0.6557, 0.6457, 0.6384, 0.6624, 0.6608, 0.6395, 0.6583],
          [0.6622, 0.6612, 0.6638, 0.6575, 0.6458, 0.6573, 0.6637, 0.6626],
          [0.6613, 0.6616, 0.6628, 0.6344, 0.6469, 0.6381, 0.6611, 0.6638]],

         [[0.6461, 0.6409, 0.6479, 0.6634, 0.6613, 0.6574, 0.6648, 0.6550],
          [0.6341, 0.6640, 0.6401, 0.6633, 0.6590, 0.6369, 0.6638, 0.6359],
          [0.6448, 0.6543, 0.6498, 0.6605, 0.6422, 0.6384, 0.6506, 0.6582],
          [0.6587, 0.6595, 0.6554, 0.6583, 0.6448, 0.6405, 0.6570, 0.6655],
          [0.6581, 0.6610, 0.6562, 0.6561, 0.6609, 0.6524, 0.6544, 0.6581],
          [0.6631, 0.6567, 0.6560, 0.6458, 0.6642, 0.6628, 0.6447, 0.6573],
          [0.6580, 0.6572, 0.6577, 0.6349, 0.6646, 0.6603, 0.6354, 0.6620],
          [0.6600, 0.6529, 0.6450, 0.6565, 0.6573, 0.6589, 0.6473, 0.6600]],

         [[0.6536, 0.6560, 0.6541, 0.6623, 0.6617, 0.6612, 0.6496, 0.6589],
          [0.6580, 0.6561, 0.6601, 0.6599, 0.6648, 0.6490, 0.6653, 0.6577],
          [0.6598, 0.6578, 0.6609, 0.6593, 0.6593, 0.6374, 0.6528, 0.6607],
          [0.6584, 0.6596, 0.6590, 0.6413, 0.6497, 0.6648, 0.6556, 0.6491],
          [0.6356, 0.6622, 0.6576, 0.6623, 0.6509, 0.6627, 0.6629, 0.6522],
          [0.6628, 0.6507, 0.6577, 0.6607, 0.6511, 0.6509, 0.6564, 0.6392],
          [0.6607, 0.6632, 0.6625, 0.6602, 0.6640, 0.6571, 0.6382, 0.6625],
          [0.6628, 0.6611, 0.6499, 0.6505, 0.6539, 0.6638, 0.6528, 0.6571]]],


        [[[0.6492, 0.6592, 0.6481, 0.6593, 0.6593, 0.6644, 0.6640, 0.6633],
          [0.6594, 0.6626, 0.6617, 0.6458, 0.6449, 0.6628, 0.6636, 0.6588],
          [0.6623, 0.6625, 0.6640, 0.6416, 0.6383, 0.6485, 0.6520, 0.6571],
          [0.6601, 0.6592, 0.6589, 0.6572, 0.6591, 0.6512, 0.6609, 0.6539],
          [0.6631, 0.6573, 0.6544, 0.6611, 0.6490, 0.6555, 0.6456, 0.6553],
          [0.6606, 0.6596, 0.6567, 0.6602, 0.6615, 0.6446, 0.6628, 0.6371],
          [0.6429, 0.6610, 0.6645, 0.6515, 0.6637, 0.6501, 0.6597, 0.6589],
          [0.6403, 0.6623, 0.6513, 0.6589, 0.6406, 0.6562, 0.6634, 0.6479]],

         [[0.6594, 0.6609, 0.6622, 0.6601, 0.6601, 0.6550, 0.6592, 0.6588],
          [0.6635, 0.6620, 0.6609, 0.6529, 0.6510, 0.6563, 0.6585, 0.6616],
          [0.6596, 0.6541, 0.6570, 0.6460, 0.6559, 0.6610, 0.6396, 0.6571],
          [0.6642, 0.6641, 0.6646, 0.6604, 0.6555, 0.6568, 0.6613, 0.6472],
          [0.6619, 0.6610, 0.6536, 0.6444, 0.6502, 0.6617, 0.6575, 0.6572],
          [0.6582, 0.6385, 0.6623, 0.6614, 0.6418, 0.6635, 0.6546, 0.6573],
          [0.6582, 0.6377, 0.6575, 0.6650, 0.6639, 0.6448, 0.6596, 0.6504],
          [0.6601, 0.6654, 0.6593, 0.6492, 0.6514, 0.6654, 0.6648, 0.6632]],

         [[0.6527, 0.6635, 0.6498, 0.6636, 0.6604, 0.6474, 0.6374, 0.6602],
          [0.6378, 0.6616, 0.6555, 0.6515, 0.6477, 0.6430, 0.6505, 0.6616],
          [0.6579, 0.6622, 0.6618, 0.6644, 0.6603, 0.6578, 0.6544, 0.6389],
          [0.6541, 0.6618, 0.6622, 0.6543, 0.6550, 0.6352, 0.6586, 0.6564],
          [0.6645, 0.6602, 0.6630, 0.6553, 0.6567, 0.6578, 0.6598, 0.6463],
          [0.6602, 0.6517, 0.6614, 0.6605, 0.6572, 0.6650, 0.6442, 0.6619],
          [0.6398, 0.6611, 0.6601, 0.6606, 0.6396, 0.6535, 0.6499, 0.6419],
          [0.6430, 0.6610, 0.6570, 0.6569, 0.6591, 0.6547, 0.6530, 0.6419]]]])

model = PreprocessAndCalculateModel()
x = real_inputs
output_gpu = model.to(gpu_device)(x.cuda())
output_cpu = model.to(cpu_device)(x.cpu())
print(torch.allclose(output_gpu.cpu(), output_cpu, atol=1e-2))
#0  0x0000000000657f3e in at::native::empty_cpu(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) ()
#1  0x00000000007252df in at::CPUType::empty(c10::ArrayRef<long>, c10::TensorOptions const&, c10::optional<c10::MemoryFormat>) ()
#2  0x00000000006fde6d in at::Tensor at::cpp_custom_type_hack::create<PackedConvWeightsQnnp>(std::unique_ptr<PackedConvWeightsQnnp, std::default_delete<PackedConvWeightsQnnp> >, c10::TensorOptions) ()
#3  0x00000000006fc9e6 in at::native::(anonymous namespace)::QConvPackWeightInt8::qnnpack_conv_prepack(at::Tensor, c10::optional<at::Tensor>, c10::List<long>, c10::List<long>, c10::List<long>, long) [clone .isra.298] ()
#4  0x00000000006fd38e in at::native::(anonymous namespace)::QConvPackWeightInt8::operator()(at::Tensor, c10::optional<at::Tensor>, c10::List<long>, c10::List<long>, c10::List<long>, long) [clone .isra.299] ()
#5  0x00000000006fd6c9 in c10::detail::wrap_kernel_functor_boxed<at::native::(anonymous namespace)::QConvPackWeightInt8, false, void>::call(c10::OperatorKernel*, std::vector<c10::IValue, std::allocator<c10::IValue> >*) ()
#6  0x00000000010e3a81 in std::result_of<c10::impl::OperatorEntry::callBoxed(std::vector<c10::IValue, std::allocator<c10::IValue> >*) const::{lambda(c10::DispatchTable const&)#1} (c10::DispatchTable const&)>::type c10::LeftRight<c10::DispatchTable>::read<c10::impl::OperatorEntry::callBoxed(std::vector<c10::IValue, std::allocator<c10::IValue> >*) const::{lambda(c10::DispatchTable const&)#1}>(std::result_of&&) const ()
#7  0x00000000010e187f in torch::jit::(anonymous namespace)::createOperatorFromC10(c10::OperatorHandle const&)::{lambda(std::vector<c10::IValue, std::allocator<c10::IValue> >&)#1}::operator()(std::vector<c10::IValue, std::allocator<c10::IValue> >&) const ()
#8  0x00000000010ba2d8 in torch::jit::InterpreterStateImpl::runImpl(std::vector<c10::IValue, std::allocator<c10::IValue> >&) ()
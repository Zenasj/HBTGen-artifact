import torch
import torchvision
import torchvision.transforms as transforms
import torch.nn as nn
import os
import torch.nn.functional as F
gpu_device = torch.device("cuda")
cpu_device = torch.device("cpu")
class PreprocessAndCalculateModel(nn.Module):
    def __init__(self):
        super().__init__()

    def forward(self, x):

        output = torch.cholesky_inverse(x)
        return output

real_inputs = torch.Tensor([[[[-0.3595,  0.0406, -0.9984, -1.5226, -1.4119,  1.0395,  1.4167,
           -1.4159],
          [ 0.6069,  0.5169,  0.1332, -0.4590, -0.6269,  0.0503,  1.0874,
           -0.1145],
          [ 1.0107,  1.5763, -0.2455, -0.0573, -1.2327,  1.0472, -0.8035,
            1.1038],
          [ 0.7291,  1.5719,  1.2025,  1.3514,  1.5245,  0.2574, -0.7415,
           -1.4915],
          [ 0.5464, -1.1027, -0.6848, -0.3077, -0.6970,  0.0915, -1.5162,
            1.2699],
          [ 0.1294,  0.9310,  0.9783,  0.2430,  0.4647, -0.8476, -1.4138,
            1.1323],
          [ 1.2121, -0.2614, -0.2485, -1.4837,  1.1618,  0.2569,  1.0122,
           -0.8012],
          [ 1.2048, -0.5580, -0.7479,  0.4214, -1.6356,  0.3922, -0.8691,
           -0.7263]],

         [[ 0.5109, -0.8009, -0.7482,  1.2806, -0.4662, -1.5242, -1.3038,
           -1.0660],
          [ 0.9265,  1.6101,  0.0314, -1.6098,  1.6105, -0.1079,  0.5486,
           -0.0713],
          [-0.1209,  0.9043, -0.9483,  0.8324,  1.2642,  1.2841, -1.2937,
            0.4592],
          [ 0.2094,  1.6074,  1.4088, -1.3555, -0.7294, -1.0105, -0.5730,
            1.1737],
          [-1.6097, -0.5100, -0.7381, -0.6620, -1.2276,  1.4973, -1.2032,
           -1.1151],
          [-1.1677,  0.2315, -1.0990,  0.8116, -1.3304,  1.2542, -0.9868,
            1.3728],
          [ 1.5643,  0.7937,  0.7899,  0.2014, -1.7247, -1.5968, -1.6914,
           -1.0772],
          [ 0.3240,  0.1052, -1.1230, -0.4052,  1.5924,  1.6245,  0.3057,
           -0.6328]],

         [[ 0.6857, -1.1814, -0.9661,  1.2492, -1.0593,  0.0419,  0.5930,
           -0.4881],
          [-0.3937,  1.1006, -0.2001,  0.3792,  0.8819,  1.6026,  0.5410,
            0.0962],
          [ 0.2341,  0.0220,  0.0844,  1.3830,  0.6150, -1.2489,  0.9091,
           -1.8194],
          [ 1.6575, -1.3479,  1.2393, -1.1549,  1.4501, -0.1767, -0.5666,
            0.7998],
          [ 0.2759,  1.0389,  1.0811,  0.5077, -0.8982,  0.4159,  0.6916,
            0.8836],
          [ 1.1585,  1.4429,  0.0344,  1.5417,  1.5252,  1.0890, -1.4467,
           -0.2925],
          [ 0.3871, -0.1887,  1.4823, -1.5536,  1.2042, -0.6963, -1.0381,
           -1.2767],
          [-1.6172,  0.0104, -0.2206,  0.9597,  0.7499,  0.7919, -1.2412,
            0.7772]]],


        [[[ 1.3391, -1.8034,  1.3602, -1.1343,  0.8837,  1.3357,  1.4750,
           -0.3117],
          [-1.4431, -1.6747,  0.7605, -1.5685,  0.3869, -0.1695,  0.1991,
           -0.6887],
          [-0.5815,  1.3120,  1.4309, -0.7725, -1.0470, -0.9312, -0.7060,
           -1.8351],
          [ 1.4613,  1.3580, -1.1939,  1.2093,  0.4296,  0.3955,  0.0557,
            0.1387],
          [ 0.9474,  1.3092, -0.2504,  0.2180, -1.3030, -0.4226, -0.0075,
            1.3932],
          [-1.1467, -0.9559, -1.3605,  0.8655, -0.7981, -1.2833, -1.4400,
            1.0552],
          [ 0.2485,  0.0584, -0.2276, -0.8126, -0.7050,  1.0967,  0.2784,
           -1.3977],
          [ 1.4993, -0.5114, -1.3227,  0.0119, -0.2040,  0.2321,  1.5360,
            1.3970]],

         [[ 0.4153,  0.5416, -0.4537, -0.1508, -0.6726, -0.3239, -0.1768,
           -0.8060],
          [-0.2699,  1.4044,  1.2038,  0.5739, -1.6478,  0.2278, -1.3979,
            0.5374],
          [ 0.6400, -1.3668, -0.6919, -0.8454,  1.0100,  0.6009,  0.8589,
           -0.0073],
          [ 0.9168,  0.0978,  0.9258,  0.7066, -0.2742, -0.2804,  1.6309,
           -0.5109],
          [ 1.5995, -0.7041, -0.3279, -1.1202,  1.4044, -0.7997,  0.2557,
           -1.0804],
          [ 0.0965,  1.6652, -0.9478,  0.9953, -0.0787, -0.9660, -1.4581,
            0.2317],
          [-0.5445, -1.0573,  0.3283, -0.1286,  1.5832,  1.2510,  1.0049,
           -0.5605],
          [-0.0370,  1.6056, -1.0369,  1.6055,  1.0672, -0.3343, -0.8592,
            0.4316]],

         [[ 0.8968, -0.6638,  0.3254, -0.6374, -0.1472, -0.3819,  0.0802,
           -0.8671],
          [ 0.5645, -1.3019,  0.4733,  1.0679, -1.4442,  0.1296,  0.2694,
            1.2161],
          [-0.0783,  1.3319,  0.3307,  1.4404,  0.7335,  0.5090,  0.4428,
           -0.3296],
          [-0.5001,  0.8837, -0.8405, -0.2624, -0.4081, -1.0793,  0.1810,
            1.4451],
          [-1.1099,  0.1921, -1.5472, -0.0816,  0.7305, -0.6804,  0.2174,
            0.7117],
          [ 0.8521, -1.9167, -0.7560,  1.1275, -0.8698, -1.2195, -1.6247,
           -0.1912],
          [-0.2655, -1.1904, -1.2098,  1.6259,  0.9244,  0.1177, -1.4356,
           -1.4854],
          [-0.4004, -1.8890,  0.8270, -1.8382,  1.4683, -1.6963, -1.7293,
           -1.5793]]]])
model = PreprocessAndCalculateModel()
x = real_inputs
output_gpu = model.to(gpu_device)(x.cuda())
output_cpu = model.to(cpu_device)(x.cpu())
print(torch.allclose(output_gpu.cpu(), output_cpu, atol=1e-7))